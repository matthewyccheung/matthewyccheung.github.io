<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.21.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>[Project] Combination Deep Diffractive Neural Networks | Matt Y. Cheung</title>
<meta name="description" content="Deep Diffractive Neural Networks  Deep Learning as become a basic tool for image classification. Training and testing using Deep Neural Networks is an incredibly time-consuming and resource-heavy process, especially for large image datasets. Recent advances in Deep Learning Diffractive Optics have shown to potential to alleviate these problems by embedding software into hardware. Specifically, Trabelsi et al. demonstrated that a Neural Network can be trained using all complex values instead of all real values for audio applications by using basic convolutional neural network building blocks [1]. Using this result, Lin et al. successfully demonstrated image classification using a terahertz source and 3-D printed passive diffractive layers. To accomplish this, Lin et al. presented a theoretically linear network, called D2NN, by modulating complex electric fields by complex valued transmission and reflection coefficients. Thus, allowing the forward propagation step to be computed at the at light speed with great empirical accuracy, albeit linear, for the MNIST Handwritten Dataset and the MNIST Fashion Dataset [2].">


  <meta name="author" content="Matt Y. Cheung">
  
  <meta property="article:author" content="Matt Y. Cheung">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Matt Y. Cheung">
<meta property="og:title" content="[Project] Combination Deep Diffractive Neural Networks">
<meta property="og:url" content="http://localhost:4000/2020/08/01/Deep-Diffractive-Neural-Networks.html">


  <meta property="og:description" content="Deep Diffractive Neural Networks  Deep Learning as become a basic tool for image classification. Training and testing using Deep Neural Networks is an incredibly time-consuming and resource-heavy process, especially for large image datasets. Recent advances in Deep Learning Diffractive Optics have shown to potential to alleviate these problems by embedding software into hardware. Specifically, Trabelsi et al. demonstrated that a Neural Network can be trained using all complex values instead of all real values for audio applications by using basic convolutional neural network building blocks [1]. Using this result, Lin et al. successfully demonstrated image classification using a terahertz source and 3-D printed passive diffractive layers. To accomplish this, Lin et al. presented a theoretically linear network, called D2NN, by modulating complex electric fields by complex valued transmission and reflection coefficients. Thus, allowing the forward propagation step to be computed at the at light speed with great empirical accuracy, albeit linear, for the MNIST Handwritten Dataset and the MNIST Fashion Dataset [2].">







  <meta property="article:published_time" content="2020-08-01T00:00:00-05:00">






<link rel="canonical" href="http://localhost:4000/2020/08/01/Deep-Diffractive-Neural-Networks.html">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": null,
      "url": "http://localhost:4000/"
    
  }
</script>






<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Matt Y. Cheung Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css">

<!--[if IE]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single wide">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/"><img src="/images/home-solid.png" alt=""></a>
        
        <a class="site-title" href="/">
          Matt Y. Cheung
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/Publications/">Publications</a>
            </li><li class="masthead__menu-item">
              <a href="/CV/">CV</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16">
            <path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path>
          </svg>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  
    <div class="author__avatar">
      
        <img src="/images/IMG_3972%202%20copy.jpg" alt="Matt Y. Cheung" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">Matt Y. Cheung</h3>
    
    
      <div class="author__bio" itemprop="description">
        <p>I’m a PhD student in the Electrical &amp; Computer Engineering Department at Rice University working under Professor <a href="https://profiles.rice.edu/faculty/ashok-veeraraghavan">Ashok Veeraraghavan</a> in the <a href="http://computationalimaging.rice.edu/">Rice Computational Imaging Lab</a>. Broadly speaking, I’m interested solving real-world problems using fundamentals of Computational Imaging, DSP and Machine Learning.</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name">Houston, TX</span>
        </li>
      

      
        
          
            <li><a href="https://github.com/matthewyccheung" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
            <li><a href="https://scholar.google.com/citations?user=6d3hfUcAAAAJ&hl=en" rel="nofollow noopener noreferrer"><i class="fas fa-graduation-cap" aria-hidden="true"></i><span class="label">Google Scholar</span></a></li>
          
        
          
            <li><a href="https://www.linkedin.com/in/matthewyccheung/" rel="nofollow noopener noreferrer"><i class="fab fa-linkedin-in" aria-hidden="true"></i><span class="label">LinkedIn</span></a></li>
          
        
          
            <li><a href="mailto:mattyc@rice.edu" rel="nofollow noopener noreferrer"><i class="fas fa-at" aria-hidden="true"></i><span class="label">Email</span></a></li>
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="[Project] Combination Deep Diffractive Neural Networks">
    <meta itemprop="description" content=" Deep Diffractive Neural Networks Deep Learning as become a basic tool for image classification. Training and testing using Deep Neural Networks is an incredibly time-consuming and resource-heavy process, especially for large image datasets. Recent advances in Deep Learning Diffractive Optics have shown to potential to alleviate these problems by embedding software into hardware. Specifically, Trabelsi et al. demonstrated that a Neural Network can be trained using all complex values instead of all real values for audio applications by using basic convolutional neural network building blocks [1]. Using this result, Lin et al. successfully demonstrated image classification using a terahertz source and 3-D printed passive diffractive layers. To accomplish this, Lin et al. presented a theoretically linear network, called D2NN, by modulating complex electric fields by complex valued transmission and reflection coefficients. Thus, allowing the forward propagation step to be computed at the at light speed with great empirical accuracy, albeit linear, for the MNIST Handwritten Dataset and the MNIST Fashion Dataset [2].">
    <meta itemprop="datePublished" content="2020-08-01T00:00:00-05:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">[Project] Combination Deep Diffractive Neural Networks
</h1>
          

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        <time datetime="2020-08-01T00:00:00-05:00">August 1, 2020</time>
      </span>
    

    

    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
        <h4> Deep Diffractive Neural Networks </h4>
<p>Deep Learning as become a basic tool for image classification. Training and testing using Deep Neural Networks is an incredibly time-consuming and resource-heavy process, especially for large image datasets. Recent advances in Deep Learning Diffractive Optics have shown to potential to alleviate these problems by embedding software into hardware. Specifically, Trabelsi et al. demonstrated that a Neural Network can be trained using all complex values instead of all real values for audio applications by using basic convolutional neural network building blocks [1]. Using this result, Lin et al. successfully demonstrated image classification using a terahertz source and 3-D printed passive diffractive layers. To accomplish this, Lin et al. presented a theoretically linear network, called D2NN, by modulating complex electric fields by complex valued transmission and reflection coefficients. Thus, allowing the forward propagation step to be computed at the at light speed with great empirical accuracy, albeit linear, for the MNIST Handwritten Dataset and the MNIST Fashion Dataset [2].</p>

<p>I explored building Deep Diffractive Neural Networks using a combination of phase, amplitude and polarization modulation layers through simulation of coherent visible light. The results for Combination D2NNs for classification and spatial differentiation were preliminary and were not published. I have lots of code and results to show and am open to discussing them. They can be found <a href="https://github.com/matthewyccheung/D2NN">here</a></p>

<div style="text-align: center"><img src="/images/spat_diff_d2nn.png" style="width: 70%; height: 70%" /></div>
<p><br /></p>
<div style="text-align: center"><img src="/images/class_acc_d2nn.png" style="width: 70%; height: 70%" /></div>

<p>[1] Trabelsi, et al. “Deep Complex Networks.” ArXiv.org, 25 Feb. 2018, arxiv.org/abs/1705.09792.</p>

<p>[2] Lin, et al. “All-Optical Machine Learning Using Diffractive Deep Neural Networks.” ArXiv.org, 26 July 2018, arxiv.org/abs/1804.08711.</p>

        
      </section>

      <footer class="page__meta">
        
        


        
  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2020-08-01T00:00:00-05:00">August 1, 2020</time></p>


      </footer>

      

      
  <nav class="pagination">
    
      <a href="/2019/06/07/1D-Kalman-Denoising.html" class="pagination--pager" title="[Project] Signal Denoising using 1D Kalman Filters
">Previous</a>
    
    
      <a href="#" class="pagination--pager disabled">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
</div>

    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    

    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2020 Matt Y. Cheung. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>







  </body>
</html>
